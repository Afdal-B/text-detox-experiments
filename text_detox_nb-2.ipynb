{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qzvSLAzFfDG"
   },
   "outputs": [],
   "source": [
    "!venv/bin/pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZ32XIJM71jC"
   },
   "outputs": [],
   "source": [
    "!venv/bin/pip install bitsandbytes datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BYuLDCn8ZDy",
    "outputId": "c482e85f-ce00-4690-dd7c-c054b04fcd35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afdal/text-detoxification/baselines/aya_model/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"XXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "021f7a3e674c4a70bf6d83ed852e36cb",
      "02b8f2b3b5a54a72b8cb3e2ae0c54311",
      "856e9c640e0649ee899b39a50c680c61",
      "b11d5e287a4f404d878214b30bd9d40a",
      "c5df67d50feb4607984a9910df0f8827",
      "cbd641fee27948bdb5526f4a49ec69a6",
      "90e4326829024df28107d8d8a24d99b1",
      "7079ddd68010462b899fc02cf5aed37d",
      "85930dd7b3b141899cc49eb7fbef1602",
      "dff644818bf24a2e93cff012daaba66c",
      "53e45e7368f04641a52b573e872775eb"
     ]
    },
    "id": "8A2TTwvx7vgS",
    "outputId": "d131ed52-7d1d-4218-9983-8c5e27e09696"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:30<00:00,  7.58s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import os\n",
    "import torch\n",
    "os.makedirs(\"offload\", exist_ok=True)\n",
    "base_model_name = \"CohereLabs/aya-expanse-8b\"\n",
    "folder = \"./drive/MyDrive/debias/\"\n",
    "checkpoint_dir = \"iproskurina/AYA-8b-expanse-tuned-all-data\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvyHJ9T65cjr",
    "outputId": "04929210-7820-4be5-e49b-2fb3540d40e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): PeftModelForCausalLM(\n",
       "    (base_model): LoraModel(\n",
       "      (model): CohereForCausalLM(\n",
       "        (model): CohereModel(\n",
       "          (embed_tokens): Embedding(256000, 4096, padding_idx=0)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x CohereDecoderLayer(\n",
       "              (self_attn): CohereAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (mlp): CohereMLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=14336, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=14336, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLU()\n",
       "              )\n",
       "              (input_layernorm): CohereLayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (norm): CohereLayerNorm()\n",
       "          (rotary_emb): CohereRotaryEmbedding()\n",
       "        )\n",
       "        (lm_head): Linear(in_features=4096, out_features=256000, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(base_model_name,  device_map=\"auto\",\n",
    "#     offload_folder=\"offload\")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, checkpoint_dir)\n",
    "model = torch.compile(model)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRzeg3Xx8d8z"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(base_model_name,  device_map=\"auto\",\n",
    "#     offload_folder=\"offload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xO8xCKH-zK6"
   },
   "outputs": [],
   "source": [
    "def detoxify(input_text, max_new_tokens=100):\n",
    "    prompt =f\"\"\"\n",
    "    You are a text detoxification assistant. Your task is to rewrite toxic, offensive, or harmful text to make it non-toxic, respectful, and safe for all audiences.\\n\n",
    "    Instructions:\\n\n",
    "    Keep the original meaning and intent of the message.\\n\n",
    "    Maintain the original language (e.g., English, French, etc.).\\n\n",
    "    Make only the minimal necessary changes to remove any toxic, abusive, offensive, or inappropriate language.\\n\n",
    "    You cannot hallucinate\\n\n",
    "    Stop generating once the detoxified version is complete and neutral — do not add extra commentary, explanation, or continuation.\\n\n",
    "    Toxic Text:\\n\n",
    "    {input_text}\\n\n",
    "    Detoxified Version:\\n\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, pad_token_id=tokenizer.eos_token_id,temperature=1.2,num_beams=5,early_stopping=True)\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    detoxified = result.split(\"## Detoxified text:\")[-1].strip()\n",
    "    return detoxified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmLRc6qxKqd9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batch_encode(tokenizer, texts, batch_size=256, max_length=128):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer.batch_encode_plus(\n",
    "            batch,\n",
    "            max_length=max_length,\n",
    "            padding='longest',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        ).to(\"cuda\")\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        attention_mask.append(inputs['attention_mask'])\n",
    "\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_mask = torch.cat(attention_mask, dim=0)\n",
    "\n",
    "    return input_ids, attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hcd8SjR7iTEQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def detoxify_file(tsv_input_path, tsv_output_path, model, tokenizer, max_length=512, batch_size=64):\n",
    "    df = pd.read_csv(tsv_input_path, sep='\\t')\n",
    "    #print(df['lang'].unique())\n",
    "\n",
    "    #df = df[df['lang'] == \"fr\"].reset_index(drop=True)\n",
    "\n",
    "    detox_outputs = []\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "        prompts = [f\"\"\"\n",
    "You are a text detoxification assistant. Your task is to rewrite toxic, offensive, or harmful text to make it non-toxic, respectful, and safe for all audiences.\\n\n",
    "Instructions:\\n\n",
    "Keep the original meaning and intent of the message.\\n\n",
    "Maintain the original language (e.g., English, French, etc.).\\n\n",
    "Make only the minimal necessary changes to remove any toxic, abusive, offensive, or inappropriate language.\\n\n",
    "You cannot hallucinate\\n\n",
    "Stop generating once the detoxified version is complete and neutral — do not add extra commentary, explanation, or continuation.\\n\n",
    "Toxic Text:\\n\n",
    "{toxic_text}\\n\n",
    "Detoxified Version:\\n\n",
    "\"\"\" for toxic_text in batch_df[\"toxic_sentence\"]]\n",
    "\n",
    "        # Tokenize in batch\n",
    "        inputs = tokenizer.batch_encode_plus(\n",
    "            prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "        input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "\n",
    "        # Generate in batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_new_tokens=100,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                temperature=1.2,\n",
    "                do_sample=True,\n",
    "                top_p=0.9\n",
    "            )\n",
    "\n",
    "        # Decode in batch\n",
    "        decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "        for result in decoded_outputs:\n",
    "            detox_outputs.append(result)\n",
    "\n",
    "    df[\"neutral_sentence\"] = detox_outputs\n",
    "    df.to_csv(tsv_output_path, sep='\\t', index=False)\n",
    "    print(f\"Fichier sauvegardé à : {tsv_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEErW83m_7h6"
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import torch\n",
    "\n",
    "# gc.collect()                  # Python garbage collector\n",
    "# torch.cuda.empty_cache()      # Clear unused memory from PyTorch\n",
    "# torch.cuda.ipc_collect()      # Free inter-process cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pa3lVnuy-RPu"
   },
   "outputs": [],
   "source": [
    "token_lengths = df[\"toxic_sentence\"].apply(lambda x: len(tokenizer.encode(x, truncation=False)))\n",
    "max_length = token_lengths.max()\n",
    "print(f\"Maximum tokenized length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyg-jbFC8lu6",
    "outputId": "323ee6c7-d6fc-45a4-e183-d75274a8bcba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/141 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "device=\"cuda\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "df = detoxify_file(\"data/test_inputs_upd.tsv\",\"data/detoxified.tsv\",\n",
    "              model,tokenizer,max_length=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwIdrNetFfDX",
    "outputId": "2e2db463-20b7-40ea-b67c-33f9c91fe403"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic_sentence</th>\n",
       "      <th>neutral_sentence</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6190</td>\n",
       "      <td>Fillon est un fils de pute, mais possède un pr...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6339</td>\n",
       "      <td>Vitellius fils de tepu qui t a donné le droit ...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6169</td>\n",
       "      <td>que ce torche cul de Figaro pour parler des év...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6243</td>\n",
       "      <td>Quand j'ai pété mon câble au collège et que j'...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6061</td>\n",
       "      <td>Le truc c'est que la critique étrangère vient ...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     toxic_sentence  \\\n",
       "0        6190  Fillon est un fils de pute, mais possède un pr...   \n",
       "1        6339  Vitellius fils de tepu qui t a donné le droit ...   \n",
       "2        6169  que ce torche cul de Figaro pour parler des év...   \n",
       "3        6243  Quand j'ai pété mon câble au collège et que j'...   \n",
       "4        6061  Le truc c'est que la critique étrangère vient ...   \n",
       "\n",
       "                                    neutral_sentence lang  \n",
       "0  \\nYou are a text detoxification assistant. You...   fr  \n",
       "1  \\nYou are a text detoxification assistant. You...   fr  \n",
       "2  \\nYou are a text detoxification assistant. You...   fr  \n",
       "3  \\nYou are a text detoxification assistant. You...   fr  \n",
       "4  \\nYou are a text detoxification assistant. You...   fr  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uymOqx47FfDY",
    "outputId": "5b091527-f569-4139-fc76-eaf304d385e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic_sentence</th>\n",
       "      <th>neutral_sentence</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6190</td>\n",
       "      <td>Fillon est un fils de pute, mais possède un pr...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6339</td>\n",
       "      <td>Vitellius fils de tepu qui t a donné le droit ...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6169</td>\n",
       "      <td>que ce torche cul de Figaro pour parler des év...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6243</td>\n",
       "      <td>Quand j'ai pété mon câble au collège et que j'...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6061</td>\n",
       "      <td>Le truc c'est que la critique étrangère vient ...</td>\n",
       "      <td>\\nYou are a text detoxification assistant. You...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     toxic_sentence  \\\n",
       "0        6190  Fillon est un fils de pute, mais possède un pr...   \n",
       "1        6339  Vitellius fils de tepu qui t a donné le droit ...   \n",
       "2        6169  que ce torche cul de Figaro pour parler des év...   \n",
       "3        6243  Quand j'ai pété mon câble au collège et que j'...   \n",
       "4        6061  Le truc c'est que la critique étrangère vient ...   \n",
       "\n",
       "                                    neutral_sentence lang  \n",
       "0  \\nYou are a text detoxification assistant. You...   fr  \n",
       "1  \\nYou are a text detoxification assistant. You...   fr  \n",
       "2  \\nYou are a text detoxification assistant. You...   fr  \n",
       "3  \\nYou are a text detoxification assistant. You...   fr  \n",
       "4  \\nYou are a text detoxification assistant. You...   fr  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/detoxified_mini.tsv\",sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAbMPIAKpkdA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UfOawAJoKt3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_detoxified_version(df, col_name, new_col_name=\"detoxified_text\"):\n",
    "\n",
    "    def extract(text):\n",
    "        match = re.search(r\"Detoxified Version:\\s*\\n(.*)\", text)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        return None\n",
    "\n",
    "    df[new_col_name] = df[col_name].apply(extract)\n",
    "    return df\n",
    "\n",
    "df = extract_detoxified_version(df,\"neutral_sentence\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "021f7a3e674c4a70bf6d83ed852e36cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02b8f2b3b5a54a72b8cb3e2ae0c54311",
       "IPY_MODEL_856e9c640e0649ee899b39a50c680c61",
       "IPY_MODEL_b11d5e287a4f404d878214b30bd9d40a"
      ],
      "layout": "IPY_MODEL_c5df67d50feb4607984a9910df0f8827"
     }
    },
    "02b8f2b3b5a54a72b8cb3e2ae0c54311": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbd641fee27948bdb5526f4a49ec69a6",
      "placeholder": "​",
      "style": "IPY_MODEL_90e4326829024df28107d8d8a24d99b1",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "53e45e7368f04641a52b573e872775eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7079ddd68010462b899fc02cf5aed37d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "856e9c640e0649ee899b39a50c680c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7079ddd68010462b899fc02cf5aed37d",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85930dd7b3b141899cc49eb7fbef1602",
      "value": 4
     }
    },
    "85930dd7b3b141899cc49eb7fbef1602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "90e4326829024df28107d8d8a24d99b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b11d5e287a4f404d878214b30bd9d40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dff644818bf24a2e93cff012daaba66c",
      "placeholder": "​",
      "style": "IPY_MODEL_53e45e7368f04641a52b573e872775eb",
      "value": " 4/4 [00:17&lt;00:00,  3.88s/it]"
     }
    },
    "c5df67d50feb4607984a9910df0f8827": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbd641fee27948bdb5526f4a49ec69a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dff644818bf24a2e93cff012daaba66c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
